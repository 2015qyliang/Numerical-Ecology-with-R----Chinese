<font face="微软雅黑">

---

# **第六章：典型排序 -- Canonical Ordination**

---

本章内容简介：

- 6.1 目标
- 6.2 典型排序简介
- 6.3 冗余分析(Redundancy Analysis, RDA)
- 6.4 典型对应分析(Canonical Correspondence Analysis, CCA)
- 6.5 线性判别分析(Linear Discriminant Analysis, LDA)
- 6.6 其他的不对称分析(Asymmetric Analyses)
- 6.7 两个(或多个)数据集的对称分析(Symmetric Analysis)
- 6.8 典型相关分析(Canonical Correlation Analysis, CCorA)
- 6.9 共惯性分析(Co-inertia Analysis, CoIA)
- 6.10 多因素分析(Multiple Factor Analysis, MFA)
- 6.11 关于物种特征和环境
- 6.12 结论

---

## 6.1 目标


---

## 6.2 典型排序简介(Canonical Ordination Overview)


---

## 6.3 冗余分析(Redundancy Analysis, RDA)

### 6.3.1 简介

### 6.3.2 河流数据集的冗余分析(RDA)

#### 6.3.2.1 数据集的预处理

```{r}
# 解决警告信息的显示问题
# Warning: Input string not available in this locale
Sys.setlocale('LC_ALL','C')

# 导入分析包
# ade4 https://www.rdocumentation.org/packages/ade4/versions/1.7-13
# 生态型数据分析(多变量数据分析): 环境科学中的探索分析和 Euclidean 方法
# vegan https://www.rdocumentation.org/packages/vegan/versions/2.4-2
# 群落生态分析包: 排序方法, 多样性分析等
# ape https://www.rdocumentation.org/packages/ape/versions/5.3
# 系统发育与进化分析
# adegraphics https://www.rdocumentation.org/packages/adegraphics/versions/1.0-15
# 表示多变量数据的图形功能,  'ade4' 的重新集成
# adespatial https://www.rdocumentation.org/packages/adespatial/versions/0.3-4
# 多元多尺度空间分析
# cocorresp https://www.rdocumentation.org/packages/cocorresp/versions/0.4-0
# 拟合预测性和对称性共同对应分析(co-correspondence analysis, CoCA)模型, 将一个数据矩阵与另一个数据矩阵相关联
# MASS -  "Modern Applied Statistics with S" (4th edition, 2002)
# https://www.rdocumentation.org/packages/MASS/versions/7.3-51.4
# 提供 MASS 这本书中使用到的函数
# ellipse https://www.rdocumentation.org/packages/ellipse/versions/0.4.1
# 绘制椭圆或者椭圆状置信区域
# FactoMineR https://www.rdocumentation.org/packages/FactoMineR/versions/1.41
# 多变量探索性分析和数据挖掘
# rrcov https://www.rdocumentation.org/packages/rrcov/versions/1.4-7
# 稳健的位置和散点估计及鲁棒的多变量分析 ??
library(ade4)
library(adegraphics)
library(adespatial)
library(cocorresp)
library(vegan)
# library(vegan3d) # 运行容易死机
library(ape)
library(MASS)
library(ellipse)
library(FactoMineR)
library(rrcov)
```

```{r}
# 导入分析脚本与数据集
source("Functions/hcoplot.R")
source("Functions/triplot.rda.R")
source("Functions/plot.lda.R")
source("Functions/polyvars.R")
source("Functions/screestick.R")
load("Data/Doubs.RData")  
```

```{r}
spe <- spe[-8, ] # 物种数据集
env <- env[-8, ] # 环境变量数据集
spa <- spa[-8, ] # 空间位置数据集
dfs <- env[, 1] # 环境变量数据集
env2 <- env[, -1]

slo2 <- rep(".very_steep", nrow(env)) # 生成重复性的向量

# quantile() 计算向量的四分位数
# https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/quantile
slo2[env$slo <= quantile(env$slo)[4]] <- ".steep"
slo2[env$slo <= quantile(env$slo)[3]] <- ".moderate"
slo2[env$slo <= quantile(env$slo)[2]] <- ".low"
slo2 <- factor(slo2, # 因子化
               levels = c(".low", ".moderate", ".steep", ".very_steep"))
table(slo2) # 统计频数
env3 <- env2
env3$slo <- slo2
# 生理学(上游 - 下游梯度)
envtopo <- env2[, c(1 : 3)] # Physiography (upstream-downstream gradient)
names(envtopo)
envchem <- env2[, c(4 : 10)] # 水质
names(envchem)
spe.hel <- decostand(spe, "hellinger") # 物种数据集数据变换
```






#### 6.3.2.2 使用 vegan 分析包进行冗余分析(RDA)

```{r}
# https://www.rdocumentation.org/packages/klaR/versions/0.6-14/topics/rda
(spe.rda <- rda(spe.hel ~ ., env3)) # 注意观察 'spe.hel ~ .' 这种快捷方式 !!!
summary(spe.rda) # Scaling 2 (默认)
coef(spe.rda) # 冗余分析结果对象的典型系数(Canonical coefficients) 
```


#### 6.3.2.3 从 vegan 分析包的冗余分析(RDA)结果中检索&解读&可视化


```{r}
# RsquareAdj
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/RsquareAdj
(R2 <- RsquareAdj(spe.rda)$r.squared) # 从 rda 结果对象中提取未调整的 R方
(R2adj <- RsquareAdj(spe.rda)$adj.r.squared) # 从 rda 结果对象中提取调整的 R方

# 绘制三序图
# 位点得分作为环境变量的线性组合
# par(mfrow = c(2, 1))
plot(spe.rda,
  scaling = 1,
  display = c("sp", "lc", "cn"),
  main = "Triplot RDA spe.hel ~ env3 - scaling 1 - lc scores"
  )
# scores 使用某种排序方法获取物种或者位点得分
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/scores
spe.sc1 <-  scores(spe.rda, 
                   choices = 1:2, 
                   scaling = 1, 
                   display = "sp"
                   )
arrows(0, 0, 
  spe.sc1[, 1] * 0.92,
  spe.sc1[, 2] * 0.92,
  length = 0, 
  lty = 1, 
  col = "red"
  )
text(-0.75, 0.7, "a", cex = 1.5)

# Scaling 2
plot(spe.rda, 
  display = c("sp", "lc", "cn"), 
  main = "Triplot RDA spe.hel ~ env3 - scaling 2 - lc scores"
  )
# scores 使用某种排序方法获取物种或者位点得分
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/scores
spe.sc2 <- scores(spe.rda, # 默认使用 scaling = 2
                  choices = 1:2, 
                  display = "sp"
                  )
arrows(0, 0, 
  spe.sc2[, 1] * 0.92, 
  spe.sc2[, 2] * 0.92,
  length = 0,
  lty = 1,
  col = "red"
  )
text(-0.82, 0.55, "b", cex = 1.5)

# 位点得分作为加权平均值 (vegan's default)
# Scaling 1 :  distance triplot - 距离三序图
plot(spe.rda, 
  scaling = 1, 
  main = "Triplot RDA spe.hel ~ env3 - scaling 1 - wa scores"
  )
arrows(0, 0, 
  spe.sc1[, 1] * 0.92, 
  spe.sc1[, 2] * 0.92, 
  length = 0, 
  lty = 1, 
  col = "red"
  )

# Scaling 2 (default) :  correlation triplot - 相关性三序图
plot(spe.rda, 
  main = "Triplot RDA spe.hel ~ env3 - scaling 2 - wa scores")
arrows(0, 0, 
  spe.sc2[, 1] * 0.92, 
  spe.sc2[, 2] * 0.92, 
  length = 0, 
  lty = 1, 
  col = "red"
  )

# 在由轴1和2形成的排序平面中选择具有至少0.6的拟合优度的物种
# goodness 评估物种或者位点的适合度
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/goodness.cca
spe.good <- goodness(spe.rda)
sel.sp <- which(spe.good[, 2] >= 0.6)

# par(mfrow = c(2, 1))
triplot.rda(spe.rda, 
  site.sc = "lc", 
  scaling = 1, 
  cex.char2 = 0.7, 
  pos.env = 3, 
  pos.centr = 1, 
  mult.arrow = 1.1, 
  mar.percent = 0.05, 
  select.spe = sel.sp
  )
text(-0.92, 0.72, "a", cex = 2)
triplot.rda(spe.rda, 
  site.sc = "lc", 
  scaling = 2, 
  cex.char2 = 0.7, 
  pos.env = 3, 
  pos.centr = 1, 
  mult.arrow = 1.1, 
  mar.percent = 0.05, 
  select.spe = sel.sp
  )
text(-2.82, 2, "b", cex = 2)
```


#### 6.3.2.4 对冗余分析(RDA)结果进行置换检验


```{r}
# 全局检验冗余分析结果
anova(spe.rda, 
      permutations = how(nperm = 999))
# 检验所有的典型轴(canonical axes)
anova(spe.rda, 
      by = "axis", 
      permutations = how(nperm = 999))

# The Kaiser-Guttman rule states that components based on eigenvalues greater than 1 should be retained. This is based on the notion that, since the sum of the eigenvalues is p, an eigenvalue larger than 1 represents an ``above average’’ component.
# http://www.statpower.net/Content/312/R%20Stuff/PCA.html
# 将Kaiser-Guttman准则应用于残余轴
# 特征值只与残差特征值的平均值进行比较
spe.rda$CA$eig[spe.rda$CA$eig > mean(spe.rda$CA$eig)]
```


#### 6.3.2.5 偏(部分)冗余分析(Partial RDA)



```{r}
(spechem.physio <- rda(spe.hel, envchem, envtopo))
summary(spechem.physio)

# https://www.rdocumentation.org/packages/klaR/versions/0.6-14/topics/rda
(spechem.physio2 <- 
  rda(spe.hel ~ pH + har + pho + nit + amm + oxy + bod 
      + Condition(ele + slo + dis), data = env2))

# 检验偏冗余分析
anova(spechem.physio2, 
      permutations = how(nperm = 999))
anova(spechem.physio2, 
      permutations = how(nperm = 999), 
      by = "axis")

# 绘制偏冗余分析的三序图
# Scaling 1 -- distance triplot
# par(mfrow = c(2, 1))
triplot.rda(spechem.physio, 
  site.sc = "lc", 
  scaling = 1, 
  cex.char2 = 0.8, 
  pos.env = 3, 
  mar.percent = 0
  )
text(-0.58, 0.64, "a", cex = 2)
# Scaling 2 -- correlation triplot
triplot.rda(spechem.physio, 
  site.sc = "lc", 
  scaling = 2, 
  cex.char2 = 0.8, 
  pos.env = 3, 
  mult.spe = 1.1, 
  mar.percent = 0.04
  )
text(-3.34, 3.44, "b", cex = 2)
```



```{r}
# Scaling 1 -- 距离? distance
plot(spechem.physio, 
     scaling = 1, 
     display = c("sp", "lc", "cn"), 
     main = "Triplot RDA spe.hel ~ chem | Topo - scaling 1 - lc scores")
# scores 使用某种排序方法获取物种或者位点得分
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/scores
spe3.sc <- 
  scores(spechem.physio, 
         choices = 1:2, 
         scaling = 1, # <<<--- 
         display = "sp"
         )
arrows(0, 0, 
  spe3.sc[, 1] * 0.92, 
  spe3.sc[, 2] * 0.92, 
  length = 0, 
  lty = 1, 
  col = "red"
  )

# Scaling 2 -- 相关性 ? correlation
plot(spechem.physio, 
     display = c("sp", "lc", "cn"), 
     main = "Triplot RDA spe.hel ~ chem | Topo - scaling 2 - lc scores")
# scores 使用某种排序方法获取物种或者位点得分
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/scores
spe4.sc <- 
  scores(spechem.physio, # 默认 Scaling 2 
  choices = 1:2, 
  display = "sp"
  )
arrows(0, 0, 
  spe4.sc[, 1] * 0.88, 
  spe4.sc[, 2] * 0.88, 
  length = 0, 
  lty = 1, 
  col = "red"
  )
```


#### 6.3.2.6 选择解释性变量


```{r}
# 方差通胀系数(Variance inflation factors, VIF) 
# 除了 dfs 其他的所有环境变量; (该章中的第一冗余分析结果?)
vif.cca(spe.rda)
# 偏冗余分析(Partial RDA – 生理学变量 physiographic variables only)
vif.cca(spechem.physio) 

# # https://www.rdocumentation.org/packages/klaR/versions/0.6-14/topics/rda
spe.rda.all <- rda(spe.hel ~ ., 
                   data = env2)
# 全局调整 R方
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/RsquareAdj
(R2a.all <- RsquareAdj(spe.rda.all)$adj.r.squared)

# 使用 forward.sel() 进行前向选择
# https://www.rdocumentation.org/packages/adespatial/versions/0.3-4/topics/forward.sel
# 通过简化模型下的残差置换来执行前向选择 - 针对多元变量
forward.sel(spe.hel, env2, 
            adjR2thresh = R2a.all)

# 使用 ordistep() 进行前向选择; 允许使用因子
mod0 <- rda(spe.hel ~ 1, 
            data = env2)
# ordistep 在约束排序(cca, rda, capscale)中通过置换检验选择模型
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/ordistep
step.forward <- 
  ordistep(mod0, 
           scope = formula(spe.rda.all), 
           direction = "forward", 
           permutations = how(nperm = 499)
           )
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/RsquareAdj
RsquareAdj(step.forward)

# 使用 vegan 中的 ordistep() 函数进行向后消除; 默认使用 - 向后消除 backward
# ordistep 在约束排序(cca, rda, capscale)中通过置换检验选择模型
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/ordistep
step.backward <-
  ordistep(spe.rda.all,
           permutations = how(nperm = 499))
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/RsquareAdj
RsquareAdj(step.backward)

# 使用 vegan 中的 ordistep() 函数进行前向选择
# 使用双重停止标准(a double stopping criterion) (Blanchet et al. 2008a)
# 环境变量中仅包含定量变量
# ordistep 在约束排序(cca, rda, capscale)中通过置换检验选择模型
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/ordistep
step2.forward <- 
  ordiR2step(mod0, 
             scope = formula(spe.rda.all), 
             direction = "forward", 
             R2scope = TRUE,
             permutations = how(nperm = 199)
             )
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/RsquareAdj
RsquareAdj(step2.forward)

# 使用 vegan 中的 ordistep() 函数进行前向选择
# using a double stopping criterion (Blanchet et al. 2008a)
# and object env3 containing a factor.
mod00 <- rda(spe.hel ~ 1, 
             data = env3)
spe.rda2.all <- rda(spe.hel ~ ., 
                    data = env3)
# ordistep 在约束排序(cca, rda, capscale)中通过置换检验选择模型
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/ordistep
step3.forward <- 
  ordiR2step(mod00, 
             scope = formula(spe.rda2.all), 
             direction = "forward", 
             permutations = how(nperm = 199)
             )
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/RsquareAdj
RsquareAdj(step3.forward)

# 完全模型的调整R方 比 仅仅与定量变量相关的完全冗余分析 要小
# 数据转换过程中可能会导致部分信息丢失
# 带有变量 slo 的部分前向选择保持不变
mod0p <- rda(spe.hel ~ Condition(slo), data = env2)
mod1p <- rda(spe.hel ~ . + Condition(slo), data = env2)
# ordistep 在约束排序(cca, rda, capscale)中通过置换检验选择模型
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/ordistep
step.p.forward <- 
  ordiR2step(mod0p, 
             scope = formula(mod1p), 
             direction = "forward", 
             permutations = how(nperm = 199)
             )
```


```{r}
# 吝啬冗余分析 - Parsimonious RDA
(spe.rda.pars <- rda(spe.hel ~ ele + oxy + bod, 
                     data = env2))
anova(spe.rda.pars, 
      permutations = how(nperm = 999))
anova(spe.rda.pars, 
      permutations = how(nperm = 999), 
      by = "axis")
(R2a.pars <- RsquareAdj(spe.rda.pars)$adj.r.squared)
# 比较方差通胀因子(Compare the variance inflation factors)
vif.cca(spe.rda.all)
vif.cca(spe.rda.pars)

# 吝啬冗余分析的三序图(带有拟合的位点得分)
# par(mfrow = c(2, 1))
# Scaling 1 -- 距离
triplot.rda(spe.rda.pars, 
  site.sc = "lc", 
  scaling = 1, 
  cex.char2 = 0.8, 
  pos.env = 2, 
  mult.spe = 0.9, 
  mult.arrow = 0.92, 
  mar.percent = 0.01
  )
# Scaling 2 -- 相关性
triplot.rda(spe.rda.pars, 
  site.sc = "lc", 
  scaling = 2, 
  cex.char2 = 0.8, 
  pos.env = 2, 
  mult.spe = 1.1, 
  mar.percent = -0.02
  )
```



```{r}
# 绘制吝啬冗余分析的三序图
# par(mfrow = c(1, 2))
# Scaling 1 -- distance 距离
plot(spe.rda.pars, 
     scaling = 1, 
     display = c("sp", "lc", "cn"), 
     main = "Triplot RDA spe.hel ~ ele+oxy+bod - scaling 1 - lc scores")
# scores 使用某种排序方法获取物种或者位点得分
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/scores
spe4.sc <- 
  scores(spe.rda.pars, 
         choices = 1:2, 
         scaling = 1, 
         display = "sp"
         )
arrows(0, 0, 
  spe4.sc[, 1] * 0.92, 
  spe4.sc[, 2] * 0.92, 
  length = 0, 
  lty = 1, 
  col = "red"
  )

# Scaling 2 -- correlation 相关性
plot(spe.rda.pars, 
     display = c("sp", "lc", "cn"), 
     main = "Triplot RDA spe.hel ~ ele+oxy+bod - scaling 2 - lc scores")
# scores 使用某种排序方法获取物种或者位点得分
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/scores
spe5.sc <- 
  scores(spe.rda.pars, # 默认 Scaling 2
         choices = 1:2, 
         display = "sp"
         )
arrows(0, 0, 
  spe5.sc[, 1] * 0.9, 
  spe5.sc[, 2] * 0.9, 
  length = 0, 
  lty = 1, 
  col = "red"
  )
```


#### 6.3.2.7 环境重构(Environmental Reconstruction): 在冗余分析中设计新位点评估解释性变量的值

```{r}
# 借助鱼类物种丰度数据虚拟分析对象
# 变量(物种)必须与原始数据的标签相匹配
site1.new <- round(apply(spe[1:15, ], 2, mean)) # 列方向 | 小数点位数
site2.new <- round(apply(spe[16:29, ], 2, mean)) # 列方向 | 小数点位数
obj.new <- t(cbind(site1.new, site2.new)) # 转置数据
obj.new.hel <- decostand(obj.new, "hel") # 数据变换

# Calibration
calibrate(spe.rda.pars, 
          obj.new.hel)

# 比较位点数据 
env2[7:9, c(1, 9, 10)]
env2[22:24, c(1, 9, 10)]
```



#### 6.3.2.8 方差分解(Variation Partitioning)



```{r}
# 两组解释变量的方差分解
# 可选颜色的分类标签
par(mfrow = c(1, 3), mar = c(1, 1, 1, 1))
# 类似于'venn 图'
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/varpart
showvarparts(2, bg = c("red", "blue"))
showvarparts(3, bg = c("red", "blue", "yellow"))
showvarparts(4, bg = c("red", "blue", "yellow", "green"))

# 1. 所有可解释变量的方差分解(除了 dfs)
(spe.part.all <- varpart(spe.hel, envchem, envtopo))
# 绘制分解结果(partitioning results) 
plot(spe.part.all, digits = 2, bg = c("red", "blue"))


# 2. 可解释变量正向选择(前向选择)之后进行方差分解 
# 每个环境变量子集中单独进行前向(正向)选择
spe.chem <- rda(spe.hel, envchem)
R2a.all.chem <- RsquareAdj(spe.chem)$adj.r.squared
forward.sel(spe.hel, 
  envchem, 
  adjR2thresh = R2a.all.chem, 
  nperm = 9999
  )
spe.topo <- rda(spe.hel, envtopo)
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/RsquareAdj
R2a.all.topo <- RsquareAdj(spe.topo)$adj.r.squared
forward.sel(spe.hel, 
  envtopo, 
  adjR2thresh = R2a.all.topo, 
  nperm = 9999
  )

# 基于前向选择的解释性变量的简单(Parsimonious, 吝啬)子集 
names(envchem)
envchem.pars <- envchem[, c(4, 6, 7)]
names(envtopo)
envtopo.pars <- envtopo[, c(1, 2)]

# 方差分解 - Variation partitioning
# varpart 分解群落矩阵的方差
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/varpart
(spe.part <- varpart(spe.hel, 
                     envchem.pars, 
                     envtopo.pars))
plot(spe.part, 
  digits = 2, 
  bg = c("red", "blue"), 
  Xnames = c("Chemistry", "Physiography"), 
  id.size = 0.7
  )

# 检验所有可检验的部分
# Test of fraction [a+b]
anova(rda(spe.hel, envchem.pars), 
      permutations = how(nperm = 999))
# Test of fraction [b+c]
anova(rda(spe.hel, envtopo.pars), 
      permutations = how(nperm = 999))
# Test of fraction [a+b+c]
env.pars <- cbind(envchem.pars, envtopo.pars)
anova(rda(spe.hel, env.pars), 
      permutations = how(nperm = 999))
# Test of fraction [a]
anova(rda(spe.hel, envchem.pars, envtopo.pars), 
      permutations = how(nperm = 999)
      )
# Test of fraction [c]
anova(rda(spe.hel, envtopo.pars, envchem.pars), 
      permutations = how(nperm = 999)
      )

## 3. 无 'nit' 变量的方差分解(Variation partitioning without the 'nit' variable)
envchem.pars2 <- envchem[, c(6, 7)]
# varpart 分解群落矩阵的方差
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/varpart
(spe.part2 <- varpart(spe.hel, 
                      envchem.pars2, 
                      envtopo.pars))
plot(spe.part2, 
     digits = 2)
```


#### 6.3.2.9 冗余分析(RDA)可作为多元方差分析(Multivariate ANOVA)的一种工具


```{r}
# 双向多元方差分析(Two-way MANOVA by RDA)

# 创建向量 'elevation' (3 levels, 9 sites each)
ele.fac <- gl(3, 9, labels = c("high", "mid", "low"))
# 创建一个模拟 'pH' 的因子
pH.fac <- 
  as.factor(c(1, 2, 3, 2, 3, 1, 3, 2, 1, 2, 1, 3, 3, 2, 
              1, 1, 2, 3, 2, 1, 2, 3, 2, 1, 1, 3, 3))
# 双向因子化设计的是否平衡 ?
table(ele.fac, pH.fac) # 列联表

# model.matrix 创建矩阵
# https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/model.matrix
(ele.pH.helm <- 
  model.matrix(~ ele.fac * pH.fac, 
               contrasts = list(ele.fac = "contr.helmert", 
                                pH.fac = "contr.helmert"))[, -1])
(ele.pH.helm2 <- 
  model.matrix(~ ele.fac + pH.fac, 
     contrasts = list(ele.fac = "contr.helmert", 
                      pH.fac = "contr.helmert"))[, -1])
colnames(ele.pH.helm2)

# 检查 helmert 对比属性 1 : 所有变量总和等于 0
apply(ele.pH.helm, 2, sum) # 按照列方向
# 检查 helmert 对比属性 2 : 组间组内的交叉集为 0 (factors & interaction)
# ?crossprod
crossprod(ele.pH.helm)

# 使用 vegan 中的 betadisper() 验证组内协方差矩阵的多元变量同质性
# 为了避免由于在另一个因素中的分散（在相互作用的情况下）相对于一个因子的方差的异质性，产生跨越两个因子的因子，即定义数据的逐个细胞属性 -- google translate
# To avoid the rist of heterogeneity of variances with respect to one factor because of the dispersion in the other (in case of interaction), creation of a factor crossing the two factors, i.e. defining the cell-by-cell attribution of the data

cell.fac <- gl(9, 3) # 创建因子水平, 向量形式保存; 9 个数, 每个重复 3 次 
spe.hel.d1 <- dist(spe.hel[1:27, ]) # 计算距离矩阵

# 检验组内分散的同质性
# 群体分散的多元同质性 - https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/betadisper
(spe.hel.cell.MHV <- betadisper(spe.hel.d1, 
                                cell.fac))
anova(spe.hel.cell.MHV) # 参数测试 - Parametric test (not recommended here)
permutest(spe.hel.cell.MHV) # 置换检验

# 在每个因子内检验分散的同质性
# 这些检验对于小样本更加稳健
# Factor "elevation"
# 群体分散的多元同质性 betadisper
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/betadisper
(spe.hel.ele.MHV <- betadisper(spe.hel.d1, ele.fac))
anova(spe.hel.ele.MHV) # 参数测试 - Parametric test (not recommended here)
permutest(spe.hel.ele.MHV) # 置换检验(Permutation test)

# Factor "pH"
# 群体分散的多元同质性 betadisper
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/betadisper
(spe.hel.pH.MHV <- betadisper(spe.hel.d1, pH.fac))
anova(spe.hel.pH.MHV) # 方差分析
permutest(spe.hel.pH.MHV) # 置换检验(Permutation test)


# 使用 rda() 步步为营进行冗余分析
# 首先检验相互影响

# 使用因子 ele & pH (列 1-4)组合成协变量(covariables)矩阵来进行检验
interaction.rda <- 
  rda(spe.hel[1:27, ], 
      ele.pH.helm[, 5:8], 
      ele.pH.helm[, 1:4])
anova(interaction.rda, 
      permutations = how(nperm = 999))

# 检验主要因子 - ele. 
# 因子 pH 和相互影响组合成协变量矩阵(matrix of covariables)
factor.ele.rda <- 
  rda(spe.hel[1:27, ], 
      ele.pH.helm[, 1:2], 
      ele.pH.helm[, 3:8])
anova(factor.ele.rda, 
      permutations = how(nperm = 999), 
      strata = pH.fac
      )

# 检验主要因子 - pH.
# 因子 ele 和相互影响组合成协变量矩阵(matrix of covariables)
factor.pH.rda <- 
  rda(spe.hel[1:27, ], 
      ele.pH.helm[, 3:4], 
      ele.pH.helm[, c(1:2, 5:8)]) 
anova(factor.pH.rda, 
  permutations = how(nperm = 999), 
  strata = ele.fac
  )

# 显著因子 ele 的冗余分析 - RDA with the significant factor ele
ele.rda.out <- rda(spe.hel[1:27, ]~ ., 
                   as.data.frame(ele.fac))
# 三序图: 'wa'位点 - 因子质心; 物种 - 箭头
plot(ele.rda.out, 
  scaling = 1, 
  display = "wa", 
  main = "Multivariate ANOVA, factor elevation - scaling 1 - 
          wa scores")
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/ordihull
# 排序图中展示组或者因子水平
ordispider(ele.rda.out, ele.fac, 
  scaling = 1, 
  label = TRUE, 
  col = "blue"
  )
# scores 使用某种排序方法获取物种或者位点得分
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/scores
spe.sc1 <- 
  scores(ele.rda.out, 
  scaling = 1, 
  display = "species")
arrows(0, 0, 
  spe.sc1[, 1] * 0.3, 
  spe.sc1[, 2] * 0.3, 
  length = 0.1, 
  angle = 10, 
  col = "red"
  )
text(
  spe.sc1[, 1] * 0.3, 
  spe.sc1[, 2] * 0.3, 
  labels = rownames(spe.sc1), 
  pos = 4, 
  cex = 0.8, 
  col = "red"
  )

# 使用 adonis2() 进行置换多元方差分析(Permutational MANOVA)
# 基于距离矩阵的方差置换多元分析
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/adonis
adonis2(spe.hel[1:27, ] ~ ele.fac * pH.fac, 
  method = "euc", 
  by = "term"
  )
```


#### 6.3.2.10 冗余分析中的非线性关系



```{r}
# 冗余分析具有单个二度解释变量(a single second degree explanatory variable)

# 使用 poly() 创建 dfs矩阵 与其 正交二度项(orthogonal second degree term)
# https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/poly
# poly() 创建正交多项式
dfs.df <- poly(dfs, 2)
colnames(dfs.df) <- c("dfs", "dfs2")
# 验证多项式的正交特性 - Verify that the polynomial terms are orthogonal
cor(dfs.df) # 计算矩阵的相关性 & 方差 & 协方差

# 找出矩阵之间的显著性变量
# forward.sel 通过简化模型下的残差置换进行前向选择
# https://www.rdocumentation.org/packages/adespatial/versions/0.3-4/topics/forward.sel
forward.sel(spe.hel, dfs.df)

# 冗余分析并进行方差分析
spe.dfs.rda <- rda(spe.hel ~ ., as.data.frame(dfs.df))
anova(spe.dfs.rda)

# 绘制三序图 -- 使用 triplot.rda()
triplot.rda(spe.dfs.rda, 
  site.sc = "lc", 
  scaling = 2, 
  plot.sites = FALSE, 
  pos.env = 1, 
  mult.arrow = 0.9, 
  move.origin = c(-0.25, 0), 
  mar.percent = 0
  )

# 绘制三序图 -- 使用 plot()
plot(spe.dfs.rda, 
  scaling = 2, 
  display = c("sp", "lc", "cn"), 
  main = "Triplot RDA spe ~ dfs+dfs2 - scaling 2 - lc scores")
# scores 使用某种排序方法获取物种或者位点得分
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/scores
spe6.sc <- 
  scores(spe.dfs.rda, 
         choices = 1:2, 
         scaling = 2, 
         display = "sp")
arrows(0, 0, 
  spe6.sc[, 1] * 0.9, 
  spe6.sc[, 2] * 0.9, 
  length = 0, 
  lty = 1, 
  col = "red"
  )

# 四种物种的地图
# par(mfrow = c(2, 2))
plot(spa, 
  asp = 1, 
  col = "brown", 
  cex = spe$Satr, 
  xlab = "x (km)", 
  ylab = "y (km)", 
  main = "Brown trout"
  )
lines(spa, col = "light blue")
plot(spa, 
  asp = 1, 
  col = "brown", 
  cex = spe$Thth, 
  xlab = "x (km)", 
  ylab = "y (km)", 
  main = "Grayling"
  )
lines(spa, col = "light blue")
plot(spa, 
  asp = 1, 
  col = "brown", 
  cex = spe$Alal, 
  xlab = "x (km)", 
  ylab = "y (km)", 
  main = "Bleak"
  )
lines(spa, col = "light blue")
plot(spa, 
  asp = 1, 
  col = "brown", 
  cex = spe$Titi, 
  xlab = "x (km)", 
  ylab = "y (km)", 
  main = "Tench"
  )
lines(spa, col = "light blue")

# 所有环境变量的 多项RDA & 二度项 & 前向选择
env.square <- polyvars(env2, degr = 2)
names(env.square)
spe.envsq.rda <- rda(spe.hel ~ ., env.square)
R2ad <- RsquareAdj(spe.envsq.rda)$adj.r.squared
(spe.envsq.fwd <- 
   forward.sel(spe.hel, 
               env.square, 
               adjR2thresh = R2ad))
envsquare.red <- env.square[, sort(spe.envsq.fwd$order)]
(spe.envsq.fwd.rda <- rda(spe.hel ~., envsquare.red))
RsquareAdj(spe.envsq.fwd.rda)
summary(spe.envsq.fwd.rda)

# 三序图
triplot.rda(spe.envsq.fwd.rda, 
  site.sc = "lc", 
  scaling = 2, 
  plot.sites = FALSE, 
  pos.env = 1, 
  mult.arrow = 0.9, 
  mult.spe = 0.9,
  mar.percent = 0
  )
```


### 6.3.3 基于距离的冗余分析(Distance-Based Redundancy Analysis, db-RDA)


```{r}
colnames(ele.pH.helm) <- 
  c("ele1", "ele2", "pH1", "pH2", "ele1pH1", "ele1pH2", 
    "ele2pH1", "ele2pH2" )

# 创建协变量矩阵
covariables <- ele.pH.helm[, 3:8]

# 使用 vegan 中的 vegdist() 计算相异响应矩阵
spe.bray27 <- vegdist(spe[1:27, ], "bray")
# 或者使用 adespatial 中的 dist.ldc() 计算相异响应矩阵
spe.bray27 <- dist.ldc(spe[1:27, ], "percentdiff")

# 1. 队平方根相异矩阵进行基于距离的冗余分析 dbrda()
bray.ele.dbrda <- dbrda(
    sqrt(spe.bray27) ~ ele.pH.helm[, 1:2] + Condition(covariables))

anova(bray.ele.dbrda, 
      permutations = how(nperm = 999)) 

# 2. 使用 capscale() 对原始数据(位点 by 物种)进行 基于距离的冗余分析 
# 非约束性; [Partial] Distance-Based Redundancy Analysis
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/capscale
ele.fac. <- ele.fac
bray.env.cap <- 
  capscale(spe[1:27, ] ~ ele.fac. + Condition(covariables), 
           data = as.data.frame(ele.pH.helm), 
           distance = "bray", 
           add = "lingoes", 
           comm = spe[1:27, ])
anova(bray.env.cap, 
      permutations = how(nperm = 999))

# Plot with "wa" scores to see dispersion of sites around the factor levels
# 绘制三序图
triplot.rda(bray.env.cap, 
            site.sc = "wa", 
            scaling = 1)
```



```{r}
### 不在本书中 --> ###

# 基于距离的冗余分析 db-RDA -- 替代方案

# 1. 使用 capscale() 对原始数据(site by species)进行基于距离的冗余分析
# 代替编码(Alternate coding) with 显示协变量(explicit covariables) coming from same object as 约束性变量(the constraining variables): 
bray.env.capscale <- 
  capscale(spe[1:27, ] ~ ele1 + ele2 + 
       Condition(pH1 + pH2 + ele1pH1 + ele1pH2 + ele2pH1 + ele2pH2), 
       data = as.data.frame(ele.pH.helm), 
       distance = "bray", 
       add = "cailliez", 
       comm = spe[1:27, ])
anova(bray.env.capscale, 
      permutations = how(nperm = 999))

# 2. PCoA with Lingoes (1971) correction - 校正方式
spe.bray27.lin <- pcoa(spe.bray27, correction = "lingoes") 
spe.bray27.lingoes <- spe.bray27.lin$vectors.cor 
# 检验因子 ele. 
# 因子 pH & interaction & Helmert-coded 形成协变量矩阵
# https://www.rdocumentation.org/packages/klaR/versions/0.6-14/topics/rda  ??
spe.L.ele.dbrda <- 
  rda(spe.bray27.lingoes, 
      ele.pH.helm[, 1:2], 
      covariables) 
anova(spe.L.ele.dbrda, 
      permutations = how(nperm = 999))
# wcmdscale() 加权经典多维尺度，也称为加权主坐标分析
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/wcmdscale
spe.lingoes2 <- wcmdscale(spe.bray27, 
                          add = "lingoes") # 添加校正标准
anova(
  rda(spe.lingoes2 ~ ele.pH.helm[, 1:2] + Condition(covariables))
  )

### 不在本书中 ###
```


### 6.3.4 手写冗余分析(RDA)函数



```{r}
myRDA <- function(Y, X) {
  ## 1. 数据预处理
  Y.mat <- as.matrix(Y)
  Yc <- scale(Y.mat, scale = FALSE)

  X.mat <- as.matrix(X)
  Xcr <- scale(X.mat)

  # 提取维度信息
  n <- nrow(Y)
  p <- ncol(Y)
  m <- ncol(X)

  ## 2. 计算多元变量线性回归
  # 回归系数矩阵 (eq. 11.9)
  B <- solve(t(Xcr) %*% Xcr) %*% t(Xcr) %*% Yc

  # 拟合值矩阵 (eq. 11.10)
  Yhat <- Xcr %*% B

  # 残差矩阵
  Yres <- Yc - Yhat

  ## 3. 对拟合值进行主成分分析(PCA on fitted values)
  # 协方差矩阵 - Covariance matrix (eq. 11.12)
  S <- cov(Yhat)

  # 特征值分解 - Eigenvalue decomposition
  eigenS <- eigen(S)

  # 统计有多少典型轴 - How many canonical axes?
  kc <- length(which(eigenS$values > 0.00000001))

  # 典型轴的特征值 - Eigenvalues of canonical axes
  ev <- eigenS$values[1 : kc]
  
  # 质心化矩阵的总方差Total variance (inertia) of the centred matrix Yc
  trace = sum(diag(cov(Yc)))
  
  # 正交特征向量 - Orthonormal eigenvectors (contributions of response variables, scaling 1)
  U <- eigenS$vectors[, 1 : kc]
  row.names(U) <- colnames(Y)

  # 位点得分 (vegan's wa scores, scaling 1; eq.11.17)
  F <- Yc %*% U
  row.names(F) <- row.names(Y)

  # 位点约束性 - Site constraints (vegan's 'lc' scores, scaling 1; eq. 11.18)
  Z <- Yhat %*% U
  row.names(Z) <- row.names(Y)

  # 典型系数 - 规范系数 - Canonical coefficients (eq. 11.19)
  CC <- B %*% U
  row.names(CC) <- colnames(X)

  # 解释变量
  # 物种环境相关性 - Species-environment correlations
  corXZ <- cor(X, Z)

  # 权重对角线矩阵Diagonal matrix of weights
  D <- diag(sqrt(ev / trace))

  # 解释性变量的双序图得分 
  coordX <- corXZ %*% D    # Scaling 1
  coordX2 <- corXZ         # Scaling 2
  row.names(coordX) <- colnames(X)
  row.names(coordX2) <- colnames(X)

  # 缩放数据至 相对特征值的平方根 - Scaling to sqrt of the relative eigenvalue (for scaling 2)
  U2 <- U %*% diag(sqrt(ev))
  row.names(U2) <- colnames(Y)
  F2 <- F %*% diag(1/sqrt(ev))
  row.names(F2) <- row.names(Y)
  Z2 <- Z %*% diag(1/sqrt(ev))
  row.names(Z2) <- row.names(Y)

  # 未调整 R方
  R2 <- sum(ev/trace)
  # 调整 R方
  R2a <- 1 - ((n - 1)/(n - m - 1)) * (1 - R2)

  # 4. 对残差进行主成分分析 - PCA on residuals
  # Write your own code as in Chapter 5. It could begin 
  # with : 
  #     eigenSres <- eigen(cov(Yres))
  #     evr <- eigenSres$values

  # 5. 输出结果
  result <- 
    list(trace, R2, R2a, ev, CC, U, F, Z, coordX, 
         U2, F2, Z2, coordX2)
  names(result) <- 
    c("Total_variance", "R2", "R2adj", "Can_ev", 
      "Can_coeff", "Species_sc1", "wa_sc1", "lc_sc1", 
      "Biplot_sc1", "Species_sc2", "wa_sc2", "lc_sc2", 
      "Biplot_sc2") 
  result
  }

doubs.myRDA <- myRDA(spe.hel, env2)
summary(doubs.myRDA)

# 检索调整后的R方
doubs.myRDA$R2adj
```


---

## 6.4 典型对应分析(Canonical Correspondence Analysis, CCA)

### 6.4.1 简介

### 6.4.2 河流数据集的典型对应分析(CCA)

#### 6.4.2.1 使用 vegan 分析包进行典型对应分析(CCA)


```{r}

# 原始鱼类物种数据集的典型对应分析(Canonical Correspondence Analysis, CCA)
# 受 env3 数据集中的所有环境变量的约束
# cca - Correspondence Analysis And Redundancy Analysis
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/cca
(spe.cca <- cca(spe ~ ., env3))
summary(spe.cca)

# 未调整 & 调整 的R方
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/RsquareAdj
RsquareAdj(spe.cca)
```


#### 6.4.2.2 绘制典型对应分析的三序图(CCA Triplot)


```{r}
# par(mfrow = c(2, 1))
# Scaling 1: species scores scaled to the relative eigenvalues, sites are weighted averages of the species
# 物种得分缩放至相对特征值, 位点是物种的加权平均值
plot(spe.cca, 
  scaling = 1, 
  display = c("sp", "lc", "cn"), 
  main = "Triplot CCA spe ~ env3 - scaling 1"
  )
text(-2.3, 4.1, "a", cex = 1.5)

# 默认使用 scaling 2: site scores scaled to the relative eigenvalues, species are weighted averages of the sites
# 位点得分缩放至相对特征值, 物种是位点的加权平均指标
plot(spe.cca, 
  display = c("sp", "lc", "cn"), 
  main = "Triplot CCA spe ~ env3 - scaling 2")
text(-2.3, 2.6, "b", cex = 1.5)

# par(mfrow = c(1, 2))
# scaling 1
# 典型对应分析(CCA)的双序图, 使用位点得分, 非物种
plot(spe.cca, 
  scaling = 1, 
  display = c("lc", "cn"), 
  main = "Biplot CCA spe ~ env3 - scaling 1"
  )

# scaling 2 
# 典型对应分析(CCA)的双序图, 使用物种得分, 非物种
plot(spe.cca, 
  scaling = 2, 
  display = c("sp", "cn"), 
  main = "Biplot CCA spe ~ env3 - scaling 2"
  )
```


#### 6.4.2.3 置换检验(典型对应分析 - CCA, 前向选择 - Forward Selection, 吝啬典型对应分析 - Parsimonious CCA)


```{r}
# 对所有的分析进行置换检验
anova(spe.cca, 
      permutations = how(nperm = 999))
# 对每个轴进行置换检验
anova(spe.cca, by = "axis", 
      permutations = how(nperm = 999))

# 使用 vegan 的 ordistep() 函数进行 基于典型对应分析(CCA)的前向选择
cca.step.forward <- 
  ordistep(cca(spe ~ 1, data = env3), 
           scope = formula(spe.cca), 
           direction = "forward", 
           permutations = how(nperm = 199))


# 使用 ele, oxy and bod 4个变量进行吝啬典型对应分析(Parsimonious CCA)
spe.cca.pars <- cca(spe ~ ele + oxy + bod, data = env3)
anova(spe.cca.pars, 
      permutations = how(nperm = 999))
anova(spe.cca.pars, 
      permutations = how(nperm = 999), by = "axis")
# R-square – like statistics | 未调整, 调整? R方
RsquareAdj(spe.cca.pars)
# 比较方差的通胀系数 - Compare variance inflation factors
vif.cca(spe.cca)
vif.cca(spe.cca.pars)
```


```{r}
# compute CCA-based variation partitioning  with bootstrap adjusted R-square
# 计算基于典型对应分析的方差分解(自展分析, 调整的R方)
# 该函数仅限制与两个可解释矩阵
varpart.cca <- function(Y, X, W) {
  # 计算 3 个典型对应分析结果
    yx.cca <- cca(Y, X)
    yw.cca <- cca(Y, W)
    yxw.cca <- cca(Y, cbind(X, W))

  # 计算调整的'惯性值' - inertia
    fract.ab <- RsquareAdj(yx.cca)$adj.r.squared
    fract.bc <- RsquareAdj(yw.cca)$adj.r.squared
    fract.abc <- RsquareAdj(yxw.cca)$adj.r.squared
    fract.a <- fract.abc-fract.bc
    fract.b <- fract.ab-fract.a
    fract.c <- fract.abc-fract.ab
    fract.d <- 1-fract.abc

  # 输出结果
    res <- matrix(0, 7, 1)
    rownames(res) <- 
        c("[ab]", "[bc]", "[abc]", "[a]", "[b]", "[c]", "[d]")
    colnames(res) <- "Value"
    res[1, 1] <- round(fract.ab, 4)
    res[2, 1] <- round(fract.bc, 4)
    res[3, 1] <- round(fract.abc, 4)
    res[4, 1] <- round(fract.a, 4)
    res[5, 1] <- round(fract.b, 4)
    res[6, 1] <- round(fract.c, 4)
    res[7, 1] <- round(fract.d, 4)
  res
  }
```


#### 6.4.2.4 三维交互图(Three-Dimensional Interactive Plots)

```{r}
# # 绘制三维交互排序结果图
# # library(vegan3d) # 导入是容易死机
# 
# # 只绘制位点
# ordirgl(spe.cca.pars, 
#         type = "t", 
#         scaling = 1)
# 
# # 连接加权平均得分与线性组合分数 combination scores
# orglspider(spe.cca.pars, scaling = 1, col = "purple")
# 
# # 位点经过聚类分析之后分成 4 组, 并使用不同的颜色进行标识
# gr <- cutree(hclust(vegdist(spe.hel, "euc"), "ward.D2"), 4)
# ordirgl(spe.cca.pars, 
#   type = "t", 
#   scaling = 1, 
#   ax.col = "black", 
#   col = gr + 1
#   )
# # 连接位点与分组的质心
# orglspider(spe.cca.pars, 
#            gr, 
#            scaling = 1)
# 
# # 绘制 3D 典型对应分析三序图
# # ordirgl(spe.cca.pars, type = "t", scaling = 2)
# # orgltext(spe.cca.pars, 
# #   display = "species", 
# #   type = "t", 
# #   scaling = 2, 
# #   col = "cyan"
# #   )
# 
# # 绘制物种分组 (Jaccard 相异矩阵)
# gs <- 
#   cutree(
#       hclust(vegdist(t(spe), method = "jaccard"), "ward.D2"), 
#       k = 4)
# ordirgl(spe.cca.pars, 
#          display = "species", 
#          type = "t", 
#          col = gs + 1)
```


---

## 6.5 线性判别分析(Linear Discriminant Analysis, LDA)

### 6.5.1 简介

### 6.5.2 使用 lda() 进行判别分析 

```{r}
gr <- cutree(hclust(vegdist(spe.hel, "euc"), # 相异矩阵
                    "ward.D2"), # Ward 最小方差聚类分析
             k = 4) # 分成 4 组

# 只含有 3 个变量的环境数据集
env.pars2 <- as.matrix(env2[, c(1, 9, 10)])

# 使用 vegan 中的 betadisper() 验证组内协方差矩阵的(covariance matrices)多元变量同质性
env.pars2.d1 <- dist(env.pars2)
# 群体分散的多元同质性
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/betadisper
(env.MHV <- betadisper(env.pars2.d1, gr))
anova(env.MHV)
permutest(env.MHV)  # 置换检验

# 对数转换变量 ele & bod
env.pars3 <- cbind(log(env2$ele), env2$oxy, log(env2$bod))
colnames(env.pars3) <- c("ele.ln", "oxy", "bod.ln") 
rownames(env.pars3) <- rownames(env2)
env.pars3.d1 <- dist(env.pars3)
# 群体分散的多元同质性
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/betadisper
(env.MHV2 <- betadisper(env.pars3.d1, gr))
permutest(env.MHV2) # 置换检验

# Preliminary test :  do the means of the explanatory variable differ among groups?

# Compute Wilk'S lambda test
# 第一种方法: Wilks.test() of package rrcov, χ2 test
# https://www.rdocumentation.org/packages/rrcov/versions/1.4-7/topics/Wilks.test
Wilks.test(env.pars3, gr)
# 第二种方法: 多元方差分析 manova(), uses an F-test approximation
# Multivariate Analysis Of Variance
# https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/manova
lw <-  manova(env.pars3 ~ as.factor(gr))

summary(lw, test = "Wilks")

env.pars3.df <- as.data.frame(env.pars3)
(spe.lda <- lda(gr ~ ele.ln + oxy + bod.ln, 
                data = env.pars3.df))
summary(spe.lda)

# 展示 3 个变量的组平均值
spe.lda$means

# 提取非标准化的识别函数 (matrix C, eq. 11.33 in Legendre and Legendre 2012)
(C <- spe.lda$scaling)

# Classification of two new objects (identification)
# A new object is created with two sites: 
#     (1) ln(ele) = 6.8, oxygen = 9 and ln(bod) = 0.8 
# and (2) ln(ele) = 5.5, oxygen = 10 and ln(bod) = 1.0
newo <- data.frame(c(6.8, 5.5), c(9, 10), c(0.8, 1))
colnames(newo) <- colnames(env.pars3)
newo
# https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/predict
# 模型预测
(predict.new <- predict(spe.lda, 
                        newdata = newo))

## Computation of LDA - discrimination functions (on standardized 
## variables)
# scale() 对矩阵相似对象进行缩放或者居中
# https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/scale
# 默认 center = T, 减去列平均值然后 centered
env.pars3.sc <- as.data.frame(scale(env.pars3.df))

# https://www.rdocumentation.org/packages/MASS/versions/7.3-51.4/topics/lda
# 线性判别分析
spe.lda2 <- lda(gr ~ ., 
                data = env.pars3.sc)

# 展示对 3 个变量的组平均值
spe.lda2$means

# 提取分类功能
(C2 <- spe.lda2$scaling)

# 计算典型特征值 - canonical eigenvalues
spe.lda2$svd^2

# Position the objects in the space of the canonical variates
# https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/predict
# 模型预测
(Fp2 <- predict(spe.lda2)$x)
# 替代方法:  Fp2 <- as.matrix(env.pars3.sc) %*% C2

# 对象的分类
# 模型预测 predict
# https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/predict
(spe.class2 <- predict(spe.lda2)$class)

# 属于该组的后验概率
# (rounded for easier interpretation)
(spe.post2 <- round(predict(spe.lda2)$posterior, 2))

# 列联表 - 先验 prior vs 预测分类 predicted classifications
(spe.table2 <- table(gr, spe.class2)) 

# 正确分类的百分比
# ?diag - 矩阵对角线
# prop.table - Express Table Entries As Fraction Of Marginal Table
# 快速表条目作为边际表的分数
# https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/prop.table
diag(prop.table(spe.table2, 1))

# Plot the LDA results using the homemade function plot.lda()
 
plot.lda(lda.out = spe.lda2, 
  groups = gr, 
  plot.sites = 2, 
  plot.centroids = 1, 
  mul.coef = 2.35
  )

# LDA with jackknife-based classification (i.e., leave-one-out cross-validation)
# 线性判别分析 - 留一交叉验证
# https://www.rdocumentation.org/packages/MASS/versions/7.3-51.4/topics/lda
(spe.lda.jac <- 
  lda(gr ~ ele.ln + oxy + bod.ln, 
      data = env.pars3.sc, 
      CV = TRUE))
summary(spe.lda.jac)

# 正确分类的数量和比例 - 列联表
spe.jac.class <- spe.lda.jac$class
spe.jac.table <- table(gr, spe.jac.class) # 列联表
# 分类成功
# ?diag - 矩阵对角线
# prop.table - Express Table Entries As Fraction Of Marginal Table
# 快速表条目作为边际表的分数
# https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/prop.table
diag(prop.table(spe.jac.table, 1))
```


```{r}
# 不在本书中 -->>
# 示例数据
grY <- c(1, 1, 1, 2, 2, 3, 3)
x1 <- c(1, 2, 2, 8, 8, 8, 9)
x2 <- c(2, 2, 1, 7, 6, 3, 3)
X <- as.data.frame(cbind(x1, x2))

# 非标准化识别函数的计算 - Computation of unstandardized identification functions
unstand.lda <- lda(grY ~ ., 
                   data = X)

# 标准化判别函数的计算 - Computation of standardized discriminant functions
X.sc <- as.data.frame(scale(X))
stand.lda <- lda(grY ~ ., 
                 data = X.sc)

# <<--不在本书中 
```


---

## 6.6 其他的非对称分析(Asymmetric Analyses)

### 6.6.1 主响应曲线(Principal Response Curves, PRC)


```{r}
# 导入数据 (vegan 内置)
data(pyrifos)
head(pyrifos)

# 创建时间因子和处理因子 - time (week) & treatment (dose). 
# 创建附加因子 - "ditch", 表示'围格', 用与测试目的
week <-
  gl(11, 12, 
     labels = c(-4, -1, 0.1, 1, 2, 4, 8, 12, 15, 19, 24))
dose <- 
  factor(rep(c(0.1, 0, 0, 0.9, 0, 44, 6, 0.1, 44, 0.9, 0, 6), 
         11))
ditch <- gl(12, 1, length = 132)

# Modified RDA - 调整过的冗余分析
# ?prc - Principal Response Curves, PRC 主响应曲线
# 冗余分析的特例
(mod <- prc(pyrifos, dose, week))
summary(mod)

# PRC plot; 仅报告了具有大的总（对数转换）丰度的物种
(logabu <- colSums(pyrifos))
class(logabu) # 向量
plot(mod, select = logabu > 200)

# 统计检验
# 因子 ditches 随机化; 时间序列, 仅对第一轴感兴趣
ctrl <- 
  how(plots = Plots(strata = ditch, type = "free"), 
      within = Within(type = "series"), 
      nperm = 999)
anova(mod, 
      permutations = ctrl, 
      first = TRUE)
```


### 6.6.2 共对应分析(Co-correspondence Analysis, CoCA)

```{r}
data(bryophyte)
data(vascular)

# method = "predictive" 默认
# method = c("predictive", "symmetric") 预测 & 对称
# https://www.rdocumentation.org/packages/cocorresp/versions/0.4-0/topics/coca
# 拟合共对应分析模型 - 共对应分析(Co-correspondence Analysis, CoCA)
(carp.pred <- coca(bryophyte ~ ., 
                   data = vascular))

# 留一交叉验证 - Leave-one-out cross-validation
# 预测性共对应分析的交叉验证
# https://www.rdocumentation.org/packages/cocorresp/versions/0.4-0/topics/crossval
crossval(bryophyte, vascular)

# 置换检验 - Permutation test
(carp.perm <- permutest(carp.pred, 
                        permutations = 99))

# 改装(refit) - 只有两个重要的轴
(carp.pred <- coca(bryophyte ~ ., 
                   data = vascular, 
                   n.axes = 2))

# 提取信息- -位点得分 & 物种符合 species loadings
# https://www.rdocumentation.org/packages/cocorresp/versions/0.4-0/topics/loadings
# loadings - 从拟合的对象中提取物种负荷
carp.scores <- scores(carp.pred)
load.bryo <- carp.pred$loadings$Y
load.plant <- carp.pred$loadings$X

# ?plot.predcoca  
# https://www.rdocumentation.org/packages/cocorresp/versions/0.4-0/topics/plot.predcoca
# 绘制响应值和预测值的双序图(该部分结果来自预测性协同对应分析, co-correspondence analysis)
par(mfrow = c(1, 2))
plot(carp.pred, 
  type = "none", 
  main = "Bryophytes", 
  xlim = c(-2, 3), 
  ylim = c(-3, 2)
  )
points(carp.scores$sites$X, 
       pch = 16, 
       cex = 0.5)
text(load.bryo, 
  labels = rownames(load.bryo), 
  cex = 0.7, 
  col = "red"
  ) 
plot(carp.pred, 
  type = "none", 
  main = "Vascular plants", 
  xlim = c(-2, 3), 
  ylim = c(-3, 2)
  )
points(carp.scores$sites$X, 
       pch = 16, 
       cex = 0.5)
text(load.plant, 
  labels = rownames(load.plant), 
  cex = 0.7, 
  col = "blue"
  ) 

# 未避免分析包中函数的使用冲突, 接触 cocorresp 分析包的调用
# Detach package cocorresp to avoid conflicts with ade4:
detach("package:cocorresp", unload = TRUE)
# 或者
unloadNamespace("cocorresp")
```


---

## 6.7 两个(或者多个数据集)的对称分析(Symmetric Analysis)



---

## 6.8 典型相关分析(Canonical Correlation Analysis, CCorA)

### 6.8.1 简介

### 6.8.2 使用 CCorA() 进行典型相关分析(Canonical Correlation Analysis) 

```{r}
# 数据预处理 - 转换使变量分布近似对称(transformations to make variable distributions approximately symmetrical)
envchem2 <- envchem
envchem2$pho <- log(envchem$pho)
envchem2$nit <- sqrt(envchem$nit)
envchem2$amm <- log1p(envchem$amm)
envchem2$bod <- log(envchem$bod)
envtopo2 <- envtopo
envtopo2$ele <- log(envtopo$ele)
envtopo2$slo <- log(envtopo$slo)
envtopo2$dis <- sqrt(envtopo$dis)

# 对标准化的变量进行典型相关分析 CCorA 
# https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/CCorA
# CCorA, Canonical Correlation Analysis 典型相关分析
(chem.topo.ccora <- 
  CCorA(envchem2, envtopo2, 
        stand.Y = TRUE, 
        stand.X = TRUE, 
        permutations = how(nperm = 999))) # 置换检验

biplot(chem.topo.ccora, 
       plot.type = "biplot")
```


---

## 6.9 共惯性分析(Co-inertia Analysis, CoIA)

### 6.9.1 简介

### 6.9.2 使用 ade4 分析包的 coinertia() 进行共惯性分析(Co-inertia Analysis)

```{r}
# 使用 ade4 中的函数进行主成分分析
dudi.chem <- dudi.pca(envchem2, 
         scale = TRUE, 
         scannf = FALSE)
dudi.topo <- dudi.pca(envtopo2, 
         scale = TRUE, 
         scannf = FALSE)
# 特征值的累积相对变化
cumsum(dudi.chem$eig / sum(dudi.chem$eig))
# 特征值的累积相对变化
cumsum(dudi.topo$eig / sum(dudi.topo$eig))

# 行 权重是否相等 ?
all.equal(dudi.chem$lw, dudi.topo$lw)

# 共惯性分析 - Co-inertia analysis
# https://www.rdocumentation.org/packages/cocorresp/versions/0.4-0/topics/coinertia
# coinertia 对两个表进行双惯性分析
coia.chem.topo <- coinertia(dudi.chem, dudi.topo, 
            scannf = FALSE, 
            nf = 2)
summary(coia.chem.topo)

# 第一个特征值的相对变化 - Relative variation on first eigenvalue
coia.chem.topo$eig[1] / sum(coia.chem.topo$eig)

# 置换检验 - Permutation test 
# 置换检验的类
randtest(coia.chem.topo, 
         nrepet = 999)

plot(coia.chem.topo)
```


---

## 6.10 多因素分析(Multiple Factor Analysis, MFA)

### 6.10.1 简介

### 6.10.2 使用 FactoMineR 分析包进行多因素分析

```{r}
# 对变量的 3 个分组进行多因素分 
# 重新整合 3 个表 (Hellinger-transformed species, physiographic variables, chemical variables) - 物种 & 地形变量 & 化学变量
tab3 <- data.frame(spe.hel, envtopo, envchem)
dim(tab3)
# 每个分组中的变量数量
(grn <- c(ncol(spe), ncol(envtopo), ncol(envchem)))

# 关闭之前的图形窗口
graphics.off()
# 多因素分析计算, 绘制图形
# MFA 多因素分析
# https://www.rdocumentation.org/packages/FactoMineR/versions/1.41/topics/MFA
(t3.mfa <- MFA(
 tab3,
 group = grn,
 type = c("c", "s", "s"),
 ncp = 2,
 name.group = c("Fish community", "Physiography", "Water quality"),
 graph = T
 ))
# 多因素分析计算, 不绘制图形
(t3.mfa <- MFA(
 tab3,
 group = grn,
 type = c("c", "s", "s"),
 ncp = 2,
 name.group = c("Fish community", "Physiography", "Water quality"),
 graph = FALSE
 ))

summary(t3.mfa)
t3.mfa$ind

plot(t3.mfa,
     choix = "axes",
     habillage = "group",
     shadowtext = TRUE)
plot(
  t3.mfa,
  choix = "ind",
  partial = "all",
  habillage = "group")
plot(t3.mfa,
     choix = "var",
     habillage = "group",
     shadowtext = TRUE)
plot(t3.mfa, choix = "group")


# RV coefficients with tests (p-values above the diagonal of 
# the matrix)
rvp <- t3.mfa$group$RV
rvp[1, 2] <- coeffRV(spe.hel, scale(envtopo))$p.value
rvp[1, 3] <- coeffRV(spe.hel, scale(envchem))$p.value
rvp[2, 3] <- coeffRV(scale(envtopo), scale(envchem))$p.value
round(rvp[-4, -4], 6)
```


```{r}
# 特征值, 碎石图和破碎棒模型 - Eigenvalues, scree plot and broken stick model
ev <- t3.mfa$eig[, 1]
names(ev) <- paste("MFA", 1 : length(ev))
# ?screestick
screestick(ev, 
           las = 2)


# 替代性绘图
# 只绘制显著的变量 (相关性)
# 选择最特征的的变量
aa <- dimdesc(t3.mfa, 
              axes = 1:2, 
              proba = 0.0001)
# 绘图
varsig <- 
  t3.mfa$quanti.var$cor[unique(c(rownames(aa$Dim.1$quanti), 
              rownames(aa$Dim.2$quanti))), ]
plot(varsig[, 1:2], 
  asp = 1, 
  type = "n", 
  xlim = c(-1, 1),
  ylim = c(-1, 1)
  )
abline(h = 0, 
       lty = 3)
abline(v = 0, 
       lty = 3)
symbols(0, 
        0, 
        circles = 1, 
        inches = FALSE, 
        add = TRUE)
arrows(0, 
       0, 
       varsig[, 1], 
       varsig[, 2], 
       length = 0.08, 
       angle = 20)

for (v in 1 : nrow(varsig)) {
  if (abs(varsig[v, 1]) > abs(varsig[v, 2])) {
    if (varsig[v, 1] >=  0) 
      pos <- 4
    else 
      pos <- 2
    }
  else {
    if (varsig[v, 2] >=  0) 
      pos <- 3
    else 
      pos <- 1 
    }
  text(varsig[v, 1], 
       varsig[v, 2], 
       labels = rownames(varsig)[v], 
       pos = pos)
  }
```


---

## 6.11 关于物种特征和环境

### 6.11.1 四角法分析(The Fourth-Corner Method)

### 6.11.2 物种功能属性与环境因子关系分析( RLQ Analysis)

### 6.11.3 在 R 中的应用


```{r}
data(aravo)
dim(aravo$spe)
dim(aravo$traits)
dim(aravo$env)

# 初步分析: CA, Hill-Smith and PCA
afcL.aravo <- dudi.coa(aravo$spe, scannf = FALSE)
acpR.aravo <- dudi.hillsmith(aravo$env, 
                 row.w = afcL.aravo$lw,
                 scannf = FALSE)
acpQ.aravo <- dudi.pca(aravo$traits, 
                 row.w = afcL.aravo$cw,
                 scannf = FALSE)

# RLQ analysis
rlq.aravo <- rlq(
                 dudiR = acpR.aravo, 
                 dudiL = afcL.aravo, 
                 dudiQ = acpQ.aravo,
                 scannf = FALSE)
plot(rlq.aravo)
# Traits by environment crossed table
rlq.aravo$tab

# 单一绘图拥挤, 逐个绘制
s.label(rlq.aravo$lR, 
  plabels.boxes.draw = FALSE, 
  ppoints.alpha = 0,
  psub.text = "a",
  psub.cex = 2, 
  psub.position = "topleft"
  )
s.label(rlq.aravo$lQ, 
  plabels.boxes.draw = FALSE, 
  ppoints.alpha = 0,
  psub.text = "b",
  psub.cex = 2, 
  psub.position = "topleft"
  )
s.arrow(rlq.aravo$l1,
  psub.text = "c",
  psub.cex = 2, 
  psub.position = "topleft"
  )
s.arrow(rlq.aravo$c1,
  psub.text = "d",
  psub.cex = 2, 
  psub.position = "topleft"
  )

# 全局检验 - Global test
# 置换检验的类
# https://www.rdocumentation.org/packages/ade4/versions/1.7-13/topics/randtest
randtest(rlq.aravo, 
         nrepet = 999, 
         modeltype = 6)

# 四象限分析方法 - Fourth-corner analysis 
fourth.aravo <- fourthcorner(
                      tabR = aravo$env, 
                      tabL = aravo$spe, 
                      tabQ = aravo$traits,
                      modeltype = 6,
                      p.adjust.method.G = "none", 
                      p.adjust.method.D = "none", 
                      nrepet = 999)
# 使用 FDR 进行多重检验校正
fourth.aravo.adj <- p.adjust.4thcorner(
                      fourth.aravo,
                      p.adjust.method.G = "fdr", 
                      p.adjust.method.D = "fdr", 
                      p.adjust.D = "global") 
# 绘制显著性关联
plot(fourth.aravo.adj, 
     alpha = 0.05, 
     stat = "D2")

# Biplot combining RLQ and fourth-corner results
plot(fourth.aravo.adj, 
  x.rlq = rlq.aravo, 
  alpha = 0.05, 
  stat = "D2", 
  type = "biplot"
  )
```


```{r}
summary(fishtraits)
rownames(fishtraits)
names(spe)
names(fishtraits)
(tra <- fishtraits[ , 6:15])

# 初步分析: CA, Hill-Smith and PCA
afcL.doubs <- dudi.coa(spe, scannf = FALSE)
acpR.doubs <- dudi.hillsmith(env3,
                             row.w = afcL.doubs$lw,
                             scannf = FALSE)
acpQ.doubs <- dudi.pca(tra, 
                       row.w = afcL.doubs$cw,
                       scannf = FALSE)

# RLQ analysis
rlq.doubs <- rlq(
  dudiR = acpR.doubs, 
  dudiL = afcL.doubs, 
  dudiQ = acpQ.doubs,
  scannf = FALSE)
plot(rlq.doubs)
# 环境交叉表的特征 - Traits by environment crossed table
rlq.doubs$tab


# 单一绘图拥挤, 逐个绘制
s.label(rlq.doubs$lR, 
        plabels.boxes.draw = FALSE, 
        ppoints.alpha = 0,
        psub.text = "a",
        psub.cex = 2, 
        psub.position = "topleft"
        )
s.label(rlq.doubs$lQ, 
        plabels.boxes.draw = FALSE, 
        ppoints.alpha = 0,
        psub.text = "b",
        psub.cex = 2, 
        psub.position = "topleft"
        )
s.arrow(rlq.doubs$l1,
        psub.text = "c",
        psub.cex = 2, 
        psub.position = "topleft"
        )
s.arrow(rlq.doubs$c1,
        psub.text = "d",
        psub.cex = 2, 
        psub.position = "topleft"
        )

# 全局检测 - Global test
# randtest - 置换检验的类
# https://www.rdocumentation.org/packages/ade4/versions/1.7-13/topics/randtest
randtest(rlq.doubs, 
         nrepet = 999, 
         modeltype = 6)


# 四象限分析 - Fourth-corner analysis
# ?fourthcorner
# https://www.rdocumentation.org/packages/ade4/versions/1.7-13/topics/fourthcorner
# 对丰度数据或者二元'有-无'数据进行四象限分析
(fourth.doubs2 <- fourthcorner(
  tabR = env3,
  tabL = spe,
  tabQ = tra,
  modeltype = 2,
  p.adjust.method.G = "fdr",
  p.adjust.method.D = "fdr",
  nrepet = 4999 # 置换检验
  ))

summary(fourth.doubs2)

fourth.doubs <- fourthcorner(
  tabR = env2, 
  tabL = spe, 
  tabQ = tra,
  modeltype = 6,
  p.adjust.method.G = "none", 
  p.adjust.method.D = "none", 
  nrepet = 4999 # 置换检验
  )

# 使用 FDR 进行多重检验校正 
(fourth.doubs.adj <- p.adjust.4thcorner(
  fourth.doubs,
  p.adjust.method.G = "fdr", 
  p.adjust.method.D = "fdr", 
  p.adjust.D = "global"))

summary(fourth.doubs.adj)

plot(fourth.doubs.adj, 
     alpha = 0.05, 
     stat = "D2")
plot(fourth.doubs2, 
     stat = "D2")
plot(fourth.doubs2, 
     stat = "G")

# Biplot combining RLQ and fourth-corner results
plot(fourth.doubs.adj, 
     x.rlq = rlq.doubs, 
     alpha = 0.05, 
     stat = "D2", 
     type = "biplot"
     )

plot(fourth.doubs2,
     x.rlq = rlq.doubs,
     alpha = 0.05,
     stat = "D2",
     type = "biplot"
     )
```


---

## 6.12 结论



---

</font>
